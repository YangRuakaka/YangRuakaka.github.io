<!DOCTYPE html>
<html lang="zh-CN" class="no-js" data-theme="dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Yukun Yang | Human-AI Interaction Research</title>
  <meta name="description" content="Yukun Yang - PhD applicant in HCI / Human-AI Interaction. Research: bidirectional alignment, human-centered AI, interactive evaluation, explainability." />
  <meta name="color-scheme" content="dark light" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Playfair+Display:wght@500;600&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="assets/css/style.css" />
  <link rel="icon" type="image/svg+xml" href="assets/favicon.svg" />
  <link rel="alternate icon" href="assets/favicon.svg" />
  <meta name="apple-mobile-web-app-title" content="Yukun" />
</head>
<body>
  <!-- Layered animated wave canvas background -->
  <div id="bg">
    <canvas id="waves" aria-hidden="true"></canvas>
    <div id="bg-overlay"></div>
  </div>

  <header class="site-header" data-animate>
    <div class="logo" data-hover-magnet>
      <span class="mark">∿</span>
      <span class="name">Yukun <em>Yang</em></span>
    </div>
    <nav class="site-nav" aria-label="Primary">
      <button class="nav-toggle" aria-expanded="false" aria-label="Toggle navigation"><span></span></button>
      <ul>
        <li><a href="#about">About</a></li>
        <li><a href="#research">Research</a></li>
        <li><a href="#projects">Projects</a></li>
        <li><a href="#publications">Publications</a></li>
        <li><a href="assets/cv/Yukun_Yang_CV.pdf" class="btn-pill" target="_blank" rel="noopener">CV</a></li>
      </ul>
    </nav>
  </header>

  <main id="main" tabindex="-1">
    <section class="hero" id="home" aria-labelledby="hero-title">
      <div class="hero-grid">
        <div class="hero-inner" data-animate>
          <h1 id="hero-title">
            <span class="hi">Hi, I'm</span>
            <span class="display">Yukun <span class="wave-accent">∿</span> Yang</span>
          </h1>
          <p class="tagline">Seeking a PhD in <strong>Human–AI Interaction</strong> — focusing on bidirectional alignment.</p>
          <p class="sub">I design human–AI interfaces that help people understand, steer, and co-adapt with advanced AI models. My work examines how human values shape AI behavior — and how AI behavior, in turn, reshapes human understanding.</p>
          <div class="hero-actions">
            <a href="#research" class="btn primary">Explore Research</a>
          </div>
          <div class="scroll-indicator" aria-hidden="true"><span></span></div>
        </div>
        <figure class="hero-avatar" data-animate>
          <div class="avatar-glow"></div>
          <img src="assets/img/avatar.jpg" alt="Portrait of Yukun Yang" loading="lazy" />
          <figcaption class="visually-hidden">Portrait of Yukun Yang</figcaption>
        </figure>
      </div>
    </section>

    <section id="about" class="panel" data-animate>
      <div class="section-head">
        <h2>About</h2>
      </div>
      <div class="split">
        <div>
          <p>I study how humans and AI systems co-adapt over time, and how interaction design can make this process transparent, value-sensitive, and aligned with real human intentions. My research focuses on enabling users to interpret AI reasoning, articulate their goals more effectively, and shape model behavior through rich, iterative interactions.</p>
          <p>I am currently seeking a PhD opportunity where I can combine empirical studies, interface design, and computational analysis to advance bidirectional alignment — ensuring that AI systems not only perform tasks, but collaborate with diverse users in ways that respect their values and context.</p>
        </div>
        <aside class="info-cards">
          <div class="card" data-tilt>
            <h3>Interests</h3>
            <ul class="tags">
              <li>Human–AI Interaction</li>
              <li>Bidirectional Alignment</li>
              <li>Interactive Evaluation</li>
              <li>Explainability & Mental Models</li>
              <li>AI Behavior Visualization</li>
            </ul>
          </div>
          <div class="card" data-tilt>
            <h3>Water Polo</h3>
            <p>My experience in water polo shapes how I think about coordination, situational awareness, and adaptive teamwork — metaphors that often inspire my approach to human–AI collaboration.</p>
          </div>
        </aside>
      </div>
    </section>

    <section id="research" class="panel" data-animate>
      <div class="section-head">
        <h2>Research Focus</h2>
      </div>
      <div class="cards-grid">
        <article class="research-card" data-tilt>
          <h3>Bidirectional Alignment</h3>
          <p>Designing interfaces that let users inspect, question, and refine AI behavior — while helping AI systems better infer human intentions and value differences.</p>
        </article>
        <article class="research-card" data-tilt>
          <h3>Interpretability as Interaction</h3>
          <p>Building explanations that are not static outputs but conversational, queryable processes that support evolving mental models.</p>
        </article>
        <article class="research-card" data-tilt>
          <h3>Human-Centered AI Evaluation</h3>
          <p>Developing evaluation frameworks that move beyond task accuracy to capture how AI behavior aligns with human values, expectations, and goals.</p>
        </article>
      </div>
    </section>

    <section id="publications" class="panel" data-animate>
      <div class="section-head">
        <h2>Publications</h2>
      </div>
      <div class="pub-gallery">
        <article class="pub-card" data-tilt>
          <div class="meta">
            <h3>Human-AI Initiative Shifts in High-Pressure Team Tasks</h3>
            <p>Study exploring dynamic control negotiation patterns between human experts and adaptive AI copilots in fast-paced analytical scenarios.</p>
            <ul class="tags small">
              <li>Human-AI Collaboration</li>
              <li>Adaptive Interfaces</li>
              <li>User Study</li>
            </ul>
          </div>
          <figure class="figure">
            <img src="assets/img/proj-adaptive.png" alt="Graph showing initiative balance oscillations" loading="lazy" />
          </figure>
        </article>
        <article class="pub-card" data-tilt>
          <div class="meta">
            <h3>Layered Explainability as an Interactive Query Process</h3>
            <p>Framework proposing multi-stage, user-driven explanation requests that adapt granularity to evolving mental models.</p>
            <ul class="tags small">
              <li>Explainability</li>
              <li>Interaction Design</li>
              <li>HCI</li>
            </ul>
          </div>
          <figure class="figure">
            <img src="assets/img/proj-lens.png" alt="Lens interface diagram with concentric layers" loading="lazy" />
          </figure>
        </article>
      </div>
    </section>

    <section id="projects" class="panel" data-animate>
      <div class="section-head">
        <h2>Selected Projects</h2>
      </div>
      <div class="cards-grid project-list">
        <article class="project-card" data-ripple>
          <div class="media"><img src="assets/img/proj-fluid.png" alt="Visualization interface" loading="lazy" /></div>
          <header><h3>DILLS: Multilevel Analysis of Multi-Agent Behavior</h3></header>
          <p>A system that analyzes high-level motives, intermediate goals, and low-level routines in multi-agent LLM workflows, helping developers diagnose misalignment and reasoning failures.</p>
          <ul class="tags small"><li>Analysis Framework</li><li>Visualization</li><li>Multi-Agent Systems</li></ul>
        </article>

        <article class="project-card" data-ripple>
          <div class="media"><img src="assets/img/proj-lens.png" alt="Explainability interface" loading="lazy" /></div>
          <header><h3>MOCHA: Counterfactual-Driven Human-in-the-Loop Annotation</h3></header>
          <p>A neuro-symbolic annotation interface that couples visual grouping with counterexample generation, helping annotators clarify concepts while teaching models more effectively.</p>
          <ul class="tags small"><li>Counterfactuals</li><li>Human-in-the-loop</li><li>CHI 2025</li></ul>
        </article>

        <article class="project-card" data-ripple>
          <div class="media"><img src="assets/img/proj-adaptive.png" alt="Web agent interface" loading="lazy" /></div>
          <header><h3>Value-Sensitive Behavior of LLM Web Agents</h3></header>
          <p>Controlled BrowserUse experiments probing how human value cues and environmental signals influence agent trajectories, reasoning, and task outcomes.</p>
          <ul class="tags small"><li>LLM Agents</li><li>Value Alignment</li><li>Interactive Evaluation</li></ul>
        </article>
      </div>
    </section>

  </main>

  <footer class="site-footer" data-animate>
    <p>&copy; <span id="year"></span> Yukun Yang. Crafted with fluid motion. Built on GitHub Pages.</p>
  </footer>

  <script>document.documentElement.classList.remove('no-js');</script>
  <script src="assets/js/waves.js" type="module"></script>
  <script src="assets/js/main.js" type="module"></script>
</body>
</html>
